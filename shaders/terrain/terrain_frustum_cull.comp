#version 450

#extension GL_GOOGLE_include_directive : require
#extension GL_KHR_shader_subgroup_ballot : require
#extension GL_KHR_shader_subgroup_arithmetic : require

/*
 * terrain_frustum_cull.comp - GPU frustum culling with stream compaction
 *
 * Culls triangles against the view frustum and writes visible indices
 * to a compact buffer for reduced subdivision dispatch size.
 *
 * Optimizations:
 *  - Uses subgroup ballot for efficient stream compaction (1 atomic per subgroup vs per thread)
 *  - Writes indirect dispatch args at end (eliminates separate prepare dispatch pass)
 */

#include "../bindings.glsl"
#include "../instancing_common.glsl"

#define CBT_BUFFER_BINDING BINDING_TERRAIN_CBT_BUFFER
#include "cbt.glsl"
#include "leb.glsl"
#include "../terrain_height_common.glsl"

layout(local_size_x = 256, local_size_y = 1, local_size_z = 1) in;

// Height map (global coarse LOD - fallback for distant terrain)
layout(binding = BINDING_TERRAIN_HEIGHT_MAP) uniform sampler2D heightMapGlobal;

// LOD tile array (high-res tiles near camera)
layout(binding = BINDING_TERRAIN_TILE_ARRAY) uniform sampler2DArray heightMapTiles;

// Tile info buffer - world bounds for each active tile
struct TileInfo {
    vec4 worldBounds;    // xy = min corner, zw = max corner
    vec4 uvScaleOffset;  // xy = scale, zw = offset
    ivec4 layerIndex;    // x = layer index in tile array, yzw = padding
};
layout(std430, binding = BINDING_TERRAIN_TILE_INFO) readonly buffer TileInfoBuffer {
    uint activeTileCount;
    uint padding1;
    uint padding2;
    uint padding3;
    TileInfo tiles[];
};

#include "../tile_cache_common.glsl"

// Uniform buffer with camera and terrain parameters
layout(std140, binding = BINDING_TERRAIN_UBO) uniform TerrainUniforms {
    mat4 viewMatrix;
    mat4 projMatrix;
    mat4 viewProjMatrix;
    vec4 frustumPlanes[6];
    vec4 cameraPosition;
    vec4 terrainParams;   // x = size, y = height scale, z = target edge pixels, w = max depth
    vec4 lodParams;       // x = split threshold, y = merge threshold, z = min depth, w = subdivisionPhase
    vec2 screenSize;
    float lodFactor;
    float padding;
};

// Visible indices buffer: [count, index0, index1, ...]
layout(std430, binding = BINDING_TERRAIN_VISIBLE_INDICES) buffer VisibleIndices {
    uint visibleCount;
    uint workgroupsCompleted;  // Atomic counter to track completed workgroups
    uint indices[];
};

// Indirect dispatch buffer for subdivision after culling (replaces separate prepare dispatch pass)
layout(std430, binding = BINDING_TERRAIN_CULL_DISPATCH) writeonly buffer CullDispatchIndirect {
    uint dispatchX;
    uint dispatchY;
    uint dispatchZ;
};

// Push constants
layout(push_constant) uniform PushConstants {
    uint subdivisionWorkgroupSize;  // Subdivision workgroup size for dispatch calculation
    uint totalWorkgroups;           // Total number of workgroups in this dispatch
    uint maxVisibleIndices;         // Output buffer capacity
    uint _pad0;
};

// Shared memory for workgroup-level aggregation
shared uint workgroupVisibleCount;
shared uint workgroupBaseSlot;
shared uint workgroupSlotsAllocated;

#define TERRAIN_SIZE (terrainParams.x)
#define HEIGHT_SCALE (terrainParams.y)

// Transform UV to world position with tile cache support
vec3 uvToWorldPos(vec2 uv) {
    vec2 worldXZ = vec2(
        (uv.x - 0.5) * TERRAIN_SIZE,
        (uv.y - 0.5) * TERRAIN_SIZE
    );
    float height = sampleHeightWithTileCache(heightMapGlobal, heightMapTiles, uv,
                                              worldXZ, HEIGHT_SCALE, activeTileCount);
    return vec3(worldXZ.x, height, worldXZ.y);
}

// Frustum culling test for AABB using shared utility
// Returns true if the AABB is completely outside the frustum (culled)
bool frustumCullAABB(vec3 minBound, vec3 maxBound) {
    return !isAABBInFrustum(frustumPlanes, minBound, maxBound);
}

void main() {
    uint leafIndex = gl_GlobalInvocationID.x;
    uint localIndex = gl_LocalInvocationID.x;
    uint totalLeaves = cbt_NodeCount();

    // Initialize shared memory
    if (localIndex == 0u) {
        workgroupVisibleCount = 0u;
    }
    barrier();

    bool visible = false;
    uint myLeafIndex = 0u;

    if (leafIndex < totalLeaves) {
        // Decode node and triangle vertices
        cbt_Node node = cbt_DecodeNode(leafIndex);
        vec2 v0, v1, v2;
        leb_DecodeTriangleVertices(node, v0, v1, v2);

        // Compute world positions for AABB
        vec3 p0 = uvToWorldPos(v0);
        vec3 p1 = uvToWorldPos(v1);
        vec3 p2 = uvToWorldPos(v2);

        // Build AABB
        vec3 minBound = min(min(p0, p1), p2);
        vec3 maxBound = max(max(p0, p1), p2);
        // Add height margin for potential terrain displacement
        minBound.y -= HEIGHT_SCALE * 0.1;
        maxBound.y += HEIGHT_SCALE * 0.1;

        // Test frustum culling
        visible = !frustumCullAABB(minBound, maxBound);
        myLeafIndex = leafIndex;
    }

    // Subgroup-level stream compaction using ballot
    // This reduces atomics from 1 per visible thread to 1 per subgroup
    uvec4 ballot = subgroupBallot(visible);
    uint subgroupVisibleCount = subgroupBallotBitCount(ballot);
    uint subgroupPrefix = subgroupBallotExclusiveBitCount(ballot);

    // First active thread in subgroup does atomic add to workgroup counter
    uint subgroupBaseOffset = 0;
    if (subgroupElect()) {
        subgroupBaseOffset = atomicAdd(workgroupVisibleCount, subgroupVisibleCount);
    }
    subgroupBaseOffset = subgroupBroadcastFirst(subgroupBaseOffset);

    // Store local offset for later write
    uint localOffset = subgroupBaseOffset + subgroupPrefix;

    // Synchronize workgroup to get final count
    barrier();

    // First thread in workgroup does atomic allocation with capacity check
    if (localIndex == 0u) {
        workgroupSlotsAllocated = 0u;
        // Use compare-and-swap to only allocate slots within buffer capacity
        uint expected = visibleCount;
        while (true) {
            uint available = (expected >= maxVisibleIndices) ? 0 : maxVisibleIndices - expected;
            workgroupSlotsAllocated = min(workgroupVisibleCount, available);
            if (workgroupSlotsAllocated == 0u) {
                workgroupBaseSlot = expected;
                break;
            }
            uint desired = expected + workgroupSlotsAllocated;
            uint actual = atomicCompSwap(visibleCount, expected, desired);
            if (actual == expected) {
                workgroupBaseSlot = expected;
                break;
            }
            expected = actual;
        }
    }
    barrier();

    // Write visible indices to global buffer (only if we got a valid slot)
    if (visible && localOffset < workgroupSlotsAllocated) {
        uint globalSlot = workgroupBaseSlot + localOffset;
        indices[globalSlot] = myLeafIndex;
    }

    // Synchronize and ensure all index writes are visible
    barrier();
    memoryBarrierBuffer();

    // Use atomic counter to detect the last workgroup to finish
    // Only the last workgroup writes dispatch args to avoid race condition
    if (localIndex == 0u) {
        // Increment completion counter and check if we're the last workgroup
        uint completed = atomicAdd(workgroupsCompleted, 1u) + 1u;

        if (completed == totalWorkgroups) {
            // We're the last workgroup - safe to read final visibleCount
            uint finalCount = visibleCount;
            dispatchX = (finalCount + subdivisionWorkgroupSize - 1u) / subdivisionWorkgroupSize;
            dispatchY = 1u;
            dispatchZ = 1u;
        }
    }
}
